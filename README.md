# caso_tiendaApp

-----


## Componentes Cr√≠ticos y Posibles Fallas en TiendApp

- Dado el contexto de TiendApp y las quejas de los clientes, es crucial establecer un monitoreo integral en varios niveles de su infraestructura.

Aqu√≠ est√°n los componentes cr√≠ticos que deber√≠an estar siendo monitoreados:

| Componente del Sistema | Tipo de Falla / Problema Potencial | Impacto en TiendApp |
|------------------------|------------------------------------|---------------------|
| **Backend (Node.js en EC2)** | **CPU alta:** Aplicaci√≥n saturada, bucles infinitos, consultas ineficientes. | Demoras en la respuesta de la aplicaci√≥n, lentitud general. |
|                        | **Memoria insuficiente:** `Out of Memory` (OOM), cuelgues del proceso Node.js. | Ca√≠das del sistema, errores 500, no se cargan productos. |
|                        | **Errores 500 en API (internos del servidor):** Fallos en el c√≥digo, excepciones no manejadas, l√≥gica de negocio defectuosa. | Transacciones fallidas (pagos, carga de productos), quejas de clientes. |
|                        | **Latencia alta en respuestas API:** Retraso en el procesamiento de solicitudes. | Lentitud en la navegaci√≥n y operaci√≥n para el usuario. |
|                        | **Fugas de memoria:** Consumo gradual e incontrolado de memoria. | Degradaci√≥n del rendimiento a lo largo del tiempo, eventuales ca√≠das. |
|                        | **Errores de conexi√≥n a servicios externos:** Fallo al comunicarse con pasarelas de pago o APIs de terceros. | Demoras en pagos, fallos en la confirmaci√≥n de pedidos. |
| **Base de Datos (PostgreSQL en RDS)** | **Conexiones m√°ximas alcanzadas:** No se pueden establecer nuevas conexiones a la base de datos. | Aplicaci√≥n no puede acceder a los datos, errores de servicio. |
|                        | **Consultas SQL lentas:** Queries no optimizadas, falta de √≠ndices. | Demoras en la carga de productos, procesamiento de pedidos lento, pagos lentos. |
|                        | **Bloqueos de base de datos:** Transacciones prolongadas que bloquean otras operaciones. | Datos inconsistentes, operaciones que no finalizan. |
|                        | **IOPS saturadas:** Disco de la base de datos no puede manejar la carga de lectura/escritura. | Degradaci√≥n severa del rendimiento de la base de datos. |
|                        | **Espacio de almacenamiento insuficiente:** Base de datos se llena y no puede escribir nuevos datos. | Fallos al crear nuevos registros (pedidos, usuarios). |
| **Frontend (React en S3 + CloudFront)** | **Errores 4xx (Cliente):** Archivos no encontrados (404), problemas de permisos (403). | La p√°gina web no carga correctamente, recursos faltantes (im√°genes, CSS, JS). |
|                        | **Errores 5xx (Servidor de CloudFront/S3):** Problemas en la distribuci√≥n de la CDN o en el bucket S3. | El sitio web completo o partes de √©l no son accesibles para el usuario. |
|                        | **Lentitud en la carga inicial de la p√°gina:** Gran tama√±o de los activos, configuraci√≥n deficiente de CloudFront. | Mala experiencia de usuario, usuarios abandonan el sitio. |
|                        | **Errores de JavaScript en el navegador:** Fallos en la l√≥gica del frontend. | Funcionalidad de la interfaz de usuario no trabaja (ej. botones no funcionan, formularios no env√≠an). |
| **Despliegue (GitHub Actions)** | **Fallo en el pipeline de despliegue:** Errores en la configuraci√≥n, dependencias faltantes, pruebas fallidas. | Nuevas versiones del software no se despliegan, errores en producci√≥n persisten. |
|                        | **Despliegues lentos:** Pipeline con demasiados pasos o pruebas ineficientes. | Retraso en la entrega de nuevas caracter√≠sticas o correcciones de errores. |
|                        | **Rollbacks fallidos:** Problemas al revertir a una versi√≥n anterior. | Mayor tiempo de inactividad durante una interrupci√≥n. |

---
## üìä M√©tricas Esenciales para el Monitoreo en TiendApp

## üìä M√©tricas Esenciales para Detectar Problemas en TiendApp

| M√©trica üìä | ¬øQu√© problema ayuda a detectar? üîç | ¬øPor qu√© es cr√≠tica? ‚ö†Ô∏è |
|------------|------------------------------------|--------------------------|
| **‚è±Ô∏è Tiempo de respuesta del API principal** | Lentitud en carga de productos y pagos | Un aumento constante puede se√±alar cuellos de botella en el backend (Node.js), afectando la experiencia del usuario. |
| **üö® N√∫mero de errores HTTP 5xx en endpoints cr√≠ticos** | Ca√≠das del sistema, fallas en pagos o carga de productos | Estos errores indican que el servidor no est√° manejando correctamente las solicitudes. Son s√≠ntomas de problemas serios en la aplicaci√≥n. |
| **üß† Uso de CPU y RAM en instancias EC2** | Inestabilidad y ca√≠das del sistema | El uso excesivo de recursos puede causar reinicios o fallos en el backend. Es clave para prever saturaci√≥n del servidor. |
| **üìâ Tasa de abandono en procesos de compra** | Interrupciones o errores en pagos | Una baja tasa de conversi√≥n o abandonos repentinos pueden revelar errores en el flujo de pago o lentitud que frustra al usuario. |
| **üóÑÔ∏è Latencia y ca√≠das en la base de datos (RDS)** | Fallos al cargar productos o procesar pedidos | Una base de datos lenta o sobrecargada puede provocar bloqueos en el sistema y demoras visibles para el usuario final. |

## Propuesta de Monitoreo para TiendApp con Prometheus y Grafana

Herramientas a Utilizar: Prometheus y Grafana

- Prometheus: Actuar√° como el motor principal de recolecci√≥n y almacenamiento de m√©tricas. Utiliza un modelo de extracci√≥n (pull) donde consulta endpoints HTTP de las aplicaciones o de exportadores (exporters) para obtener las m√©tricas. Es ideal para monitorear el estado de los servicios y recursos a lo largo del tiempo.

- Grafana: Ser√° la plataforma para la visualizaci√≥n de datos, la creaci√≥n de dashboards interactivos y la configuraci√≥n de alertas. Se integrar√° con Prometheus para consultar las m√©tricas almacenadas y presentarlas de manera comprensible y accionable.

Las alertas deben ser configuradas en Grafana utilizando Prometheus como fuente de datos. El canal de notificaci√≥n principal ser√° Slack, que ya es com√∫nmente utilizado por equipos de desarrollo.

## üîå Integraciones Necesarias (Prometheus + Grafana)

| Componente | Integraci√≥n T√©cnica |
|------------|----------------------|
| **Node.js (Backend en EC2)** | Exponer m√©tricas con `express-prometheus-middleware` en `/metrics`. Prometheus scrapea este endpoint. |
| **PostgreSQL (RDS)** | Usar `postgres_exporter` en una instancia EC2. Requiere usuario de solo lectura en la base de datos. |
| **Instancia EC2 (Backend)** | Instalar `node_exporter` para obtener m√©tricas del sistema: CPU, RAM, disco, red. |
| **Frontend (React en S3 + CloudFront)** | No se conecta directamente. M√©tricas indirectas pueden exponerse desde el backend sobre actividad de usuarios. |
| **Slack (Notificaciones)** | Configurar Alertmanager con webhook hacia un canal de Slack (`#dev-alertas`) para recibir notificaciones. |

## üìà Dashboards Principales en Grafana

| Dashboard | M√©tricas Incluidas |
|-----------|--------------------|
| **üß† Recursos del Servidor (EC2 con Node Exporter)** | - CPU (uso, load average)<br>- RAM utilizada vs disponible<br>- Disco (espacio, IOPS)<br>- Red (ingreso/egreso) |
| **‚öôÔ∏è Backend Node.js (API)** | - Latencia de endpoints<br>- Tasa de peticiones<br>- Errores HTTP 5xx/4xx<br>- Tiempo promedio por endpoint |
| **üóÑÔ∏è Base de Datos PostgreSQL** | - Conexiones activas<br>- Latencia de queries<br>- Uso de disco<br>- Locks y errores |
| **üí≥ Transacciones y Flujo de Compras (custom)** | - Tasa de √©xito de pagos (expuesta desde backend)<br>- Errores en pagos<br>- Tiempo promedio de procesamiento |
## üö® Simulaci√≥n de Alertas y Respuesta

### üîî Alertas a Configurar

| Alerta | Umbral sugerido | Frecuencia de chequeo |
|--------|------------------|------------------------|
| ‚è±Ô∏è Latencia alta en API | > 500 ms (p95) durante 5 min | Cada 1 min |
| üö® Errores HTTP 5xx > 1% | Por m√°s de 5 min consecutivos | Cada 1 min |
| üíæ CPU EC2 > 80% | Durante 10 minutos | Cada 2 min |
| üß† RAM EC2 > 85% | Uso sostenido por 10 minutos | Cada 2 min |
| üóÑÔ∏è Conexiones activas en RDS > 90% | Por 5 min continuos | Cada 1 min |
| üìâ √âxito en pagos < 95% | Durante cualquier per√≠odo de 5 min | Cada 1 min |

---

### ‚è∞ Protocolo de Respuesta Fuera del Horario Laboral

1. **Alerta se dispara en Prometheus ‚Üí Alertmanager** la env√≠a a Slack.
2. **Notificaci√≥n autom√°tica** etiqueta al equipo responsable y deja logs adjuntos.
3. Si es una alerta **cr√≠tica** (API ca√≠da, CPU al 100%, pagos fallando):
   - Se activa una **pol√≠tica de on-call** (turnos rotativos fuera de horario).
   - Se notifica v√≠a Slack + Email .
4. El **responsable on-call**:
   - Consulta el dashboard en Grafana.
   - Verifica logs.
   - Toma acci√≥n pertinentes(reinicio, rollback, escalado manual o autom√°tico).

---

### ‚öôÔ∏è Acciones Automatizadas Recomendadas

| Acci√≥n | Cu√°ndo aplicarla | C√≥mo implementarla |
|--------|------------------|---------------------|
| üîÑ Reinicio autom√°tico del backend (Node.js) | Si error 5xx persiste mayor a 5 min | Script Bash con `systemctl restart` o llamado desde webhook. |
| üìà Autoescalado de instancias EC2 | CPU > 80% por m√°s de 10 min | Usar pol√≠ticas de escalado en Auto Scaling Groups. |
| üßº Limpieza de logs o cach√© | Si uso de disco > 90% | Cron job que borra logs antiguos/locales. |
| üöß Modo mantenimiento | Si pagos caen a < 90% √©xito | Backend responde con banner a usuarios hasta resolver. |

## ‚úÖ Evaluaci√≥n y Continuidad del Sistema de Monitoreo

### üìä ¬øC√≥mo se evaluar√° el √©xito del sistema de monitoreo?

El √©xito del sistema de monitoreo se evaluar√° con base en:

- Reducci√≥n del tiempo promedio de detecci√≥n de incidentes (MTTD).
- Mejora en el tiempo de resoluci√≥n (MTTR).
- Menor dependencia de reportes de clientes para detectar problemas.
- Aumento en la estabilidad del sistema (menos ca√≠das no detectadas).
- Calidad y utilidad de los dashboards y alertas.

---

### üìà KPIs para Medir la Mejora

| KPI | Objetivo |
|-----|----------|
| üïí MTTD (Mean Time to Detect) | mayor a 2 minutos desde que ocurre un problema. |
| üõ†Ô∏è MTTR (Mean Time to Recovery) | mayor a 15 minutos en horas laborales. |
| ‚ö†Ô∏è N√∫mero de incidentes detectados por usuarios | Reducci√≥n progresiva mensual. |
| üìâ Errores 5xx por cada 10.000 requests | Mantener < 5 errores. |
| ‚úÖ Tasa de √©xito en transacciones de pago | Mantener ‚â• 98% mensualmente. |
| üì• Alertas falsas positivas |mayor a 5% del total mensual de alertas. |

---

### üîÑ Integraci√≥n con el Flujo DevOps de TiendApp

El monitoreo se integrar√° en el ciclo DevOps de TiendApp mediante:

- üì¶ **Integraci√≥n continua (CI/CD):**
  - Verificaci√≥n autom√°tica de endpoints y m√©tricas en cada despliegue.
  - Validaci√≥n de que las m√©tricas custom siguen siendo expuestas (health checks).
  
- üîÅ **Ciclo de feedback continuo:**
  - Cada incidente registrado en alertas se revisar√° en post-mortem semanales.
  - Los insights extra√≠dos se integrar√°n como mejoras en infraestructura o c√≥digo.
  
- üõ†Ô∏è **Dashboards como parte del flujo de trabajo diario:**
  - Grafana estar√° visible en pantallas de monitoreo o integrado en herramientas de comunicaci√≥n (Slack, Notion, etc.).
  
- üöÄ **Alertas en pre-producci√≥n y staging:**
  - Monitoreo tambi√©n activo en entornos previos a producci√≥n para detecci√≥n anticipada de errores.

